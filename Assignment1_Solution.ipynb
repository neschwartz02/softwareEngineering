{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SE_Assignment_01_Solution (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-Bakahc97cy"
      },
      "source": [
        "# Problem Statement\n",
        "Consider a Hero (Agent) trying to escape the matrix from the evil villan. The matrix is a supring Environment that the Hero (Agent) must solve in order to escape.\n",
        "\n",
        "The Environment is the model of a Maze Problem but with buildings \n",
        "- Here we will have a 2D matrix as our observation space\n",
        "```\n",
        "[Buildings 1, 2, 3, 4, 5\n",
        "            [1, 0, 0, 0, 0], --> Floor 5\n",
        "            [0, 0, 0, 1, 0], --> Floor 4\n",
        "            [0, 0, 0, 0, 0], --> Floor 3\n",
        "            [0, 1, 0, 0, 0], --> Floor 2\n",
        "            [0, 0, 1, 0, 1], --> Floor 1\n",
        "] \n",
        "```\n",
        "- Here each column is a building of floors ranging from 1-5, bottom to top respectively\n",
        "- Each 0 represents a closed door and each 1 represents a open door that the Hero (Agent) must reach\n",
        "- Each step we need to move to the floor in the first building where 1 i.e door is open\n",
        "- This has to be repeated for N steps, Only then will our Hero (Agent) be set free\n",
        "\n",
        "- Example, Consider that the hero has to solve for 3 steps. The following 2D building matrix\n",
        "\n",
        "```\n",
        "Current Observation: \n",
        " [[0 1 0 0 1]\n",
        " [0 0 0 1 0]\n",
        " [1 0 0 0 0]  --> We send the Hero, Floor 3 because the Door is Open i.e 1\n",
        " [0 0 1 0 0]\n",
        " [0 0 0 0 0]]\n",
        ">>> Moving to Floor 3 and Accessing Door!\n",
        "\n",
        "Current Observation: \n",
        " [[1 0 0 1 0] --> We send the Hero, Floor 5 because the Door is Open i.e 1\n",
        " [0 0 1 0 0]\n",
        " [0 0 0 0 1]\n",
        " [0 1 0 0 0]\n",
        " [0 0 0 0 0]]\n",
        ">>> Moving to Floor 5 and Accessing Door!\n",
        "\n",
        "Current Observation: \n",
        " [[0 0 1 0 0]\n",
        " [0 1 0 0 0]\n",
        " [0 0 0 1 0]\n",
        " [1 0 0 0 1] --> We send the Hero, Floor 2 because the Door is Open i.e 1\n",
        " [0 0 0 0 0]]\n",
        ">>> Moving to Floor 2 and Accessing Door!\n",
        "\n",
        "Escaped from the Evil Villan! Reward: 3.0\n",
        "```\n",
        "- In the first step Hero has to move to floor 3 because the value is 1\n",
        "- In the second step he has to move to floor 5 because the value is 1\n",
        "- In the third step he has to move to floor 2 because the value is 1\n",
        "    - Notice how each step a new building was added with a door from step 2 onwards\n",
        "    - This is randomly added every step, i.e every step the first building is taken away and a new building is added to the end of the buildings with a Door at a random floor\n",
        "\n",
        "\n",
        "\n",
        "**Our objective is to provide necessary floor number which will tell our Hero in which floor he will find the door open to escape. If we do not reach the right floor then our Hero will be caught and it is Game over!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAr3CLv7_0t6"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class Environment:\n",
        "    def __init__(self):\n",
        "        # Initialize total time steps the agent is allowed to interact with the Enviroment\n",
        "        self.total_time_steps = 0\n",
        "        self.obs = []\n",
        "        self.current_agent_floor = 5\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset the Environement total time steps for the Agent\n",
        "        # This indicates that we need to correct the stearing wheel 10 times to reach the finish line\n",
        "        self.total_time_steps = 10\n",
        "        # Consider index 0 to be distance of the car to the left side barricade\n",
        "        # index 1 to be distance of the car to the right side barricade\n",
        "        self.obs = np.zeros((5, 5), dtype=int)\n",
        "        for row_index in range(5): self.obs[random.randint(0, 4), row_index] = 1\n",
        "        return self.get_observation()\n",
        "\n",
        "    def get_observation(self):\n",
        "        # Return observation vector currently is all ones since the Environment has no internal state\n",
        "        # Usually this would return the Enviroments observation of the Agent\n",
        "        return self.obs\n",
        "\n",
        "    def get_actions(self):\n",
        "        # Return the set of actions that the Agent can perform which in this case is up and down\n",
        "        return [1, 2, 3, 4, 5]\n",
        "\n",
        "    def is_done(self):\n",
        "        # Return the total_time_steps which is used to check if the all the steps are exhausted by the Agent\n",
        "        # i.e, Indicates the end of Episode to the Agent\n",
        "        return self.total_time_steps == 0\n",
        "\n",
        "    def move_to_floor(self, to_floor):\n",
        "        self.current_agent_floor = to_floor\n",
        "        print(f\">>> Moving to Floor {self.current_agent_floor} and Accessing Door!\")        \n",
        "        self.obs[5 - self.current_agent_floor, 0] = 0\n",
        "\n",
        "    def action(self, to_floor = None):\n",
        "        # Display the current observation space\n",
        "        print(\"\\nCurrent Observation: \\n\", self.obs)\n",
        "        \n",
        "        self.move_to_floor(to_floor=to_floor)\n",
        "\n",
        "        if self.obs[:, 0].any():\n",
        "            raise Exception(f\"Oh No! You Opened the Wrong Door, Game Over! :(\\n\\n{self.obs}\")\n",
        "        else:\n",
        "            reward = 1.0\n",
        "        # Decrement the total time steps\n",
        "        self.total_time_steps -= 1\n",
        "\n",
        "        # Update the observation space\n",
        "        # Move the puzzle one step ahead\n",
        "        self.obs = self.obs[:, [1, 2, 3, 4, 0]]\n",
        "        # Add a new puzzle layer in the end\n",
        "        self.obs[:, 4] = 0\n",
        "        # Add random solution for the newly added last layer\n",
        "        self.obs[random.randint(0, 4), 4] = 1\n",
        "        \n",
        "        # Return random reward\n",
        "        return reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjD_JrK8DRmY"
      },
      "source": [
        "## Code Challenge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "U1T_1ahT8yJl",
        "outputId": "16b235c2-4173-4bfb-f077-8ed524dc70ed"
      },
      "source": [
        "# The Agent is an entity which enforces some policy which decides \n",
        "# the action for each step using it's observation against the Environment\n",
        "class Agent:\n",
        "    def __init__(self):\n",
        "        # Declare and Initialize the total reward value as 0\n",
        "        self.total_reward = 0\n",
        "        # Declare and Initialize the floor to which the Agent has to move as 1\n",
        "        self.move_to_floor = 1\n",
        "\n",
        "    def step(self, env):\n",
        "        # This main function of the Agent where the Environmental challenge is solved\n",
        "        # MAIN LOGIC TO SOLVE THE CHALLENGE\n",
        "        self.set_floor_to_move(env)\n",
        "        # Move to the floor in the enviroment\n",
        "        reward = env.action(to_floor=self.move_to_floor)\n",
        "        # Total reward is incremented\n",
        "        self.total_reward += reward\n",
        "    \n",
        "    def set_floor_to_move(self, env):\n",
        "        # **** Write code here, to set the value of `self.move_to_floor` *****\n",
        "        # Hint: Remove pass\n",
        "        pass\n",
        "\n",
        "\n",
        "# Initialize the Enviroment and Agent objects\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "# Reset the Environment to its desired initial state which will return the obeservation\n",
        "obs = env.reset()\n",
        "# Display the obseration\n",
        "print(\"**** BEGIN GAME ****\")\n",
        "# Agent keeps taking steps until the enviroment does not allow it to take any more steps\n",
        "# Note: We will not raise Exception since we check if the Environment has time steps\n",
        "#  to take before taking a step using our Agent\n",
        "while not env.is_done():\n",
        "    agent.step(env)\n",
        "\n",
        "# Display the total reward\n",
        "print(\"Reached Finish Line! Reward:\", agent.total_reward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**** BEGIN GAME ****\n",
            "\n",
            "Current Observation: \n",
            " [[0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [1 0 1 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 1 0 0 0]]\n",
            ">>> Moving to Floor 1 and Accessing Door!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-185c8502045d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#  to take before taking a step using our Agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Display the total reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-185c8502045d>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_floor_to_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Move to the floor in the enviroment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_floor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_floor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Total reward is incremented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-2dd427bf58b7>\u001b[0m in \u001b[0;36maction\u001b[0;34m(self, to_floor)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Oh No! You Opened the Wrong Door, Game Over! :(\\n\\n{self.obs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Oh No! You Opened the Wrong Door, Game Over! :(\n\n[[0 0 0 0 1]\n [0 0 0 1 0]\n [1 0 1 0 0]\n [0 0 0 0 0]\n [0 1 0 0 0]]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kZYHCKODOuC"
      },
      "source": [
        "## Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2fOQd1aGY0v",
        "outputId": "94dce4ba-720c-4cbf-8deb-b708af0ee4ab"
      },
      "source": [
        "# The Agent is an entity which enforces some policy which decides \n",
        "# the action for each step using it's observation against the Environment\n",
        "class Agent:\n",
        "    def __init__(self):\n",
        "        # Declare and Initialize the total reward value as 0\n",
        "        self.total_reward = 0\n",
        "        # Declare and Initialize the floor to which the Agent has to move as 1\n",
        "        self.move_to_floor = 1\n",
        "\n",
        "    def step(self, env):\n",
        "        # This main function of the Agent where the Environmental challenge is solved\n",
        "        # MAIN LOGIC TO SOLVE THE CHALLENGE\n",
        "        self.set_floor_to_move(env)\n",
        "        # Move to the floor in the enviroment\n",
        "        reward = env.action(to_floor=self.move_to_floor)\n",
        "        # Total reward is incremented\n",
        "        self.total_reward += reward\n",
        "    \n",
        "    def set_floor_to_move(self, env):\n",
        "        # Get the current observation space\n",
        "        current_obs = env.get_observation()\n",
        "        # Calculate the floor to move\n",
        "        ((col_index_where_value_is_one, ), ) = np.where(current_obs[:, 0][::-1]==1)\n",
        "        # Since our floor levels are from 1-5\n",
        "        self.move_to_floor = col_index_where_value_is_one + 1\n",
        "\n",
        "# Initialize the Enviroment and Agent objects\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "# Reset the Environment to its desired initial state which will return the obeservation\n",
        "obs = env.reset()\n",
        "# Display the obseration\n",
        "print(\"**** BEGIN GAME ****\")\n",
        "# Agent keeps taking steps until the enviroment does not allow it to take any more steps\n",
        "# Note: We will not raise Exception since we check if the Environment has time steps\n",
        "#  to take before taking a step using our Agent\n",
        "while not env.is_done():\n",
        "    agent.step(env)\n",
        "\n",
        "# Display the total reward\n",
        "print(\"\\nEscaped from the Evil Villan! Reward:\", agent.total_reward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**** BEGIN GAME ****\n",
            "\n",
            "Current Observation: \n",
            " [[0 0 0 0 0]\n",
            " [0 0 0 1 0]\n",
            " [1 1 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 0]]\n",
            ">>> Moving to Floor 3 and Accessing Door!\n",
            "\n",
            "Current Observation: \n",
            " [[0 0 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [1 1 0 0 0]\n",
            " [0 0 0 1 1]\n",
            " [0 0 0 0 0]]\n",
            ">>> Moving to Floor 3 and Accessing Door!\n",
            "\n",
            "Current Observation: \n",
            " [[0 0 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 1 1 1]\n",
            " [0 0 0 0 0]]\n",
            ">>> Moving to Floor 3 and Accessing Door!\n",
            "\n",
            "Current Observation: \n",
            " [[0 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 1 1 1 0]\n",
            " [0 0 0 0 1]]\n",
            ">>> Moving to Floor 4 and Accessing Door!\n",
            "\n",
            "Current Observation: \n",
            " [[0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [1 1 1 0 1]\n",
            " [0 0 0 1 0]]\n",
            ">>> Moving to Floor 2 and Accessing Door!\n",
            "\n",
            "Current Observation: \n",
            " [[0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [1 1 0 1 0]\n",
            " [0 0 1 0 1]]\n",
            ">>> Moving to Floor 2 and Accessing Door!\n",
            "\n",
            "Current Observation: \n",
            " [[0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [1 0 1 0 0]\n",
            " [0 1 0 1 1]]\n",
            ">>> Moving to Floor 2 and Accessing Door!\n",
            "\n",
            "Current Observation: \n",
            " [[0 0 0 0 1]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [1 0 1 1 0]]\n",
            ">>> Moving to Floor 1 and Accessing Door!\n",
            "\n",
            "Current Observation: \n",
            " [[0 0 0 1 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 1 1 0 1]]\n",
            ">>> Moving to Floor 2 and Accessing Door!\n",
            "\n",
            "Current Observation: \n",
            " [[0 0 1 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [1 1 0 1 1]]\n",
            ">>> Moving to Floor 1 and Accessing Door!\n",
            "\n",
            "Escaped from the Evil Villan! Reward: 10.0\n"
          ]
        }
      ]
    }
  ]
}